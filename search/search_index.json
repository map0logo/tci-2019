{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"Welcome to MkDocs \u00b6 For full documentation visit mkdocs.org . Commands \u00b6 mkdocs new [ dir - name ] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs help - Print this help message. Project layout \u00b6 mkdocs . yml # The configuration file . docs / index . md # The documentation homepage . ... # Other markdown pages , images and other files .","title":"Welcome to MkDocs"},{"location":"index.html#welcome-to-mkdocs","text":"For full documentation visit mkdocs.org .","title":"Welcome to MkDocs"},{"location":"index.html#commands","text":"mkdocs new [ dir - name ] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs help - Print this help message.","title":"Commands"},{"location":"index.html#project-layout","text":"mkdocs . yml # The configuration file . docs / index . md # The documentation homepage . ... # Other markdown pages , images and other files .","title":"Project layout"},{"location":"01cm_definiciones.html","text":"Cadenas de Markov \u00b6 Transiciones de Estado \u00b6 La secuencia de variables aleatorias x_0, x_1, x_2, \\dots, x_t , \\dots x_0, x_1, x_2, \\dots, x_t , \\dots representa un proceso estoc\u00e1stico . Cuando se indexan solamente los puntos en el tiempo en el que ocurren cambios significativos, se habla de procesos estoc\u00e1sticos de tiempo discreto . Hablamos de estado como la condici\u00f3n o caracter\u00edstica de un sistema en momento dado. Se asume que hay un n\u00famero finito de estados numerados 1, \\dots, N 1, \\dots, N que pueden describir al sistema en un cualquier momento. Cuando el sistema cambia de un estado a otro se dice que ocurre una transici\u00f3n . \\begin{equation} P (x_{t+1} = s_{t+1} | x_t = s_t , x_{t\u22121} = s_{t\u22121}, \\dots , x_1 = s_1, x_0 = s_0)\\\\ = P (x_{t+1} = s_{t+1} | x_t = s_t ) \\end{equation} \\begin{equation} P (x_{t+1} = s_{t+1} | x_t = s_t , x_{t\u22121} = s_{t\u22121}, \\dots , x_1 = s_1, x_0 = s_0)\\\\ = P (x_{t+1} = s_{t+1} | x_t = s_t ) \\end{equation} Se conoce como propiedad de Markov el hecho que la probabilidad del estado en t+1 t+1 dependa solamente del estado en t t . Y como cada x_t x_t depende tan solo de x_{t-1} x_{t-1} e influye solamente en x_{t+1} x_{t+1} se dice que el proceso es una cadena de Markov . Si, adem\u00e1s el n\u00famero de estados es numerable y finito, se habla de un cadena de Markov de estado finito . Una suposici\u00f3n adicional es que la probabilidad de transici\u00f3n de un estado i i a un estado j j es constante en el tiempo. \\begin{equation} P (x_{t+1} = j | x_t = i) = p_{ij} \\end{equation} \\begin{equation} P (x_{t+1} = j | x_t = i) = p_{ij} \\end{equation} es independiente del \u00edndice del tiempo t t , esto se conoce como la propiedad estacionaria . La probabilidad p_{ij} p_{ij} se denomina probabilidad de transici\u00f3n , al definirse para todos los estados del sistema i,j = 1, 2, \\dots, N i,j = 1, 2, \\dots, N , y se suelen escribir en una matriz de probabilidades de transici\u00f3n . \\begin{equation} \\mathbf{P} = \\begin{bmatrix} p_{11} & p_{12} & \\dots & p_{1N} \\\\ p_{21} & p_{22} & \\dots & p_{2N} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ p_{N1} & p_{N2} & \\dots & p_{NN} \\\\ \\end{bmatrix} \\end{equation} \\begin{equation} \\mathbf{P} = \\begin{bmatrix} p_{11} & p_{12} & \\dots & p_{1N} \\\\ p_{21} & p_{22} & \\dots & p_{2N} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ p_{N1} & p_{N2} & \\dots & p_{NN} \\\\ \\end{bmatrix} \\end{equation} Adem\u00e1s, los elementos de cada fila forma una distribuci\u00f3n de probabilidades discreta, por lo tanto: \\begin{equation} \\displaystyle\\sum_{j=1}^{N}p_{ij}=1 \\end{equation} \\begin{equation} \\displaystyle\\sum_{j=1}^{N}p_{ij}=1 \\end{equation} Un proceso de Markov comienza en alg\u00fan momento inicial t = 0 t = 0 . Si el estado x_0 x_0 no se conoce con certeza, entonces debemos especificar las probabilidades con las que el sistema se encuentra inicialmente en cada uno de los N N estados. Denotamos esto como P(x_0 = i) = p_i(0) P(x_0 = i) = p_i(0) para cada estado i i , y usamos el vector \\begin{equation} \\mathbf{p}(0) = [p_1(0), p_2(0), \\dots, p_N(0)] \\end{equation} \\begin{equation} \\mathbf{p}(0) = [p_1(0), p_2(0), \\dots, p_N(0)] \\end{equation} para describir la distribuci\u00f3n de probabilidad inicial del sistema. Ejemplo \u00b6 En un lugar se pueden describir los d\u00edas como soleados, nublados, y lluviosos. Despu\u00e9s de observar los patrones hist\u00f3ricos, la condici\u00f3n del clima del siguiente d\u00eda puede ser descrita de acuerdo a las siguientes probabilidades de transici\u00f3n: \\begin{equation} \\mathbf{P} = \\begin{bmatrix} 0.7 & 0.1 & 0.2 \\\\ 0.2 & 0.7 & 0.1 \\\\ 0.5 & 0.2 & 0.3 \\\\ \\end{bmatrix} \\end{equation} \\begin{equation} \\mathbf{P} = \\begin{bmatrix} 0.7 & 0.1 & 0.2 \\\\ 0.2 & 0.7 & 0.1 \\\\ 0.5 & 0.2 & 0.3 \\\\ \\end{bmatrix} \\end{equation} Las probabilidades de un paso pueden ilustrarse mediante un diagrama de transici\u00f3n de estados , en el que los estados se representan por nodos y las posibles transiciones como v\u00e9rtices . from graphviz import Digraph # Create Digraph object g = Digraph () g . attr ( rankdir = 'RL' , label = ' \\n Diagrama de transici\u00f3n' , fontsize = '16' , fontname = 'Lato' ) g . attr ( 'node' , fontsize = '10' , fontname = 'Lato' ) g . attr ( 'edge' , fontsize = '10' , fontname = 'Lato' ) # Add nodes g . node ( '1' , 'Soleado' ) g . node ( '2' , 'Nublado' ) g . node ( '3' , 'Lluvioso' ) # Add edges g . edge ( '1' , '1' , '0.7' ) g . edge ( '1' , '2' , '0.1' ) g . edge ( '1' , '3' , '0.2' ) g . edge ( '2' , '1' , '0.2' ) g . edge ( '2' , '2' , '0.7' ) g . edge ( '2' , '3' , '0.1' ) g . edge ( '3' , '1' , '0.5' ) g . edge ( '3' , '2' , '0.2' ) g . edge ( '3' , '3' , '0.3' ) # Visualize the graph g Si se desea conocer si una determinada condici\u00f3n del clima prevalece durante dos d\u00edas, se puede utilizar un \u00e1rbol de transici\u00f3n de dos pasos. g = Digraph () g . attr ( rankdir = 'LR' , label = ' \\n \u00c1rbol de transici\u00f3n' , fontsize = '16' , fontname = 'Lato' ) g . attr ( 'node' , fontsize = '10' , fontname = 'Lato' ) g . attr ( 'edge' , fontsize = '10' , fontname = 'Lato' ) g . node ( '1a' , 'Soleado' ) g . node ( '1b' , 'Soleado' ) g . node ( '2b' , 'Nublado' ) g . node ( '3b' , 'Lluvioso' ) g . node ( '1c' , 'Soleado' ) g . node ( '2c' , 'Nublado' ) g . node ( '3c' , 'Lluvioso' ) g . node ( '1d' , 'Soleado' ) g . node ( '2d' , 'Nublado' ) g . node ( '3d' , 'Lluvioso' ) g . node ( '1e' , 'Soleado' ) g . node ( '2e' , 'Nublado' ) g . node ( '3e' , 'Lluvioso' ) g . edge ( '1a' , '1b' , '0.7' ) g . edge ( '1a' , '2b' , '0.1' ) g . edge ( '1a' , '3b' , '0.2' ) g . edge ( '1b' , '1c' , '0.7' ) g . edge ( '1b' , '2c' , '0.1' ) g . edge ( '1b' , '3c' , '0.2' ) g . edge ( '2b' , '1d' , '0.2' ) g . edge ( '2b' , '2d' , '0.7' ) g . edge ( '2b' , '3d' , '0.1' ) g . edge ( '3b' , '1e' , '0.5' ) g . edge ( '3b' , '2e' , '0.2' ) g . edge ( '3b' , '3e' , '0.3' ) g Probabilidades de Estado \u00b6 Si se denota la probabilidad p_{ij}^{(n)} p_{ij}^{(n)} como la probabilidad de transici\u00f3n del estado i i al estado j j en n n pasos. El c\u00e1lculo de p_{11}^{(2)} p_{11}^{(2)} ser\u00eda \\begin{equation} (0.7)(0.7)+(0.1)(0.2)+(0.2)(0.5)\\\\ =(p_{11})(p_{11})+(p_{12})(p_{21})+(p_{13})(p_{31})\\\\ = 0.61 \\end{equation} \\begin{equation} (0.7)(0.7)+(0.1)(0.2)+(0.2)(0.5)\\\\ =(p_{11})(p_{11})+(p_{12})(p_{21})+(p_{13})(p_{31})\\\\ = 0.61 \\end{equation} Es posible generalizar que para cualquier i i y j j , p_{ij}^{(2)} p_{ij}^{(2)} es el producto interno de la i i -\u00e9sima fila de \\mathbf{P} \\mathbf{P} con la j j -\u00e9sima columna de \\mathbf{P} \\mathbf{P} . \\begin{equation} p_{ij}^{(2)} = \\sum_{k=1}^{N}p_{ik}p_{kj} \\end{equation} \\begin{equation} p_{ij}^{(2)} = \\sum_{k=1}^{N}p_{ik}p_{kj} \\end{equation} import numpy as np p = np . array ([[ 0.7 , 0.1 , 0.2 ], [ 0.2 , 0.7 , 0.1 ], [ 0.5 , 0.2 , 0.3 ]]) p array ([[ 0 . 7 , 0 . 1 , 0 . 2 ], [ 0 . 2 , 0 . 7 , 0 . 1 ], [ 0 . 5 , 0 . 2 , 0 . 3 ]]) p2 = p @ p p2 array ([[ 0 . 61 , 0 . 18 , 0 . 21 ], [ 0 . 33 , 0 . 53 , 0 . 14 ], [ 0 . 54 , 0 . 25 , 0 . 21 ]]) from IPython.display import display , Markdown display ( Markdown ( rf '$p^2_{{11}} =$ {p2[0, 0]:.2f}' )) p^2_{11} = p^2_{11} = 0.61 Lo que implica que la probabilidad que sea soleado dentro de dos d\u00edas dado que hoy es soleado es igual a 0.61 0.61 . Siendo @ en numpy el operador para la multiplicaci\u00f3n matricial o la multiplicaci\u00f3n punto, siendo p @ p equivalente a p . dot ( p ) . Se puede generalizar a\u00fan m\u00e1s esta expresi\u00f3n, llegando a lo que se conoce como la Ecuaci\u00f3n de Chapman-Kolgomorov : \\begin{equation} p_{ij}^{(n)} = p_{ij}^{n} = \\sum_{k=1}^{N}p_{ik}^{n-m}p_{kj}^m \\end{equation} \\begin{equation} p_{ij}^{(n)} = p_{ij}^{n} = \\sum_{k=1}^{N}p_{ik}^{n-m}p_{kj}^m \\end{equation} Clasificaci\u00f3n de los estados en un proceso de Markov \u00b6 Un estado j j es alcanzable desde el estado i i si hay una secuencia de transiciones que comienza en estado i i y termina en estado j j . Esto es, p^{(n)}_{ij} \\gt 0 p^{(n)}_{ij} \\gt 0 para alg\u00fan n n . Una cadena Markov irreducible es aquella en la que se puede llegar a todos los estados desde todos los dem\u00e1s estados. Es decir, en una cadena irreducible, no es posible que el proceso quede atrapado y de ah\u00ed en adelante solo pueda hacer transiciones dentro de alg\u00fan subconjunto de los estados. Se dice que un conjunto de estados est\u00e1 cerrado si no se puede llegar a ning\u00fan estado fuera del conjunto desde ning\u00fan estado dentro del conjunto. Esto significa que una vez que el sistema entra en cualquier estado en el conjunto, nunca saldr\u00e1 de este conjunto. En una cadena irreducible, sus estados constituyen un conjunto cerrado y ning\u00fan subconjunto de estos estados est\u00e1 cerrado. Un caso particularmente interesante se presenta si un conjunto cerrado contiene s\u00f3lo un estado. Este estado i i se llama estado absorbente , y p_{ii} = 1 p_{ii} = 1 . El sistema nunca deja un estado de absorci\u00f3n. Un estado i i es un estado transitorio si hay una transici\u00f3n del estado i i a otro estado j j desde la cual no se puede volver a alcanzar el estado i i . Por lo tanto, siempre que se sale de un estado transitorio, hay una probabilidad positiva de que no se vuelva a ocupar nunca m\u00e1s. Y por lo tanto, la probabilidad a largo plazo de que un sistema se encuentre en un estado transitorio es esencialmente nula porque, con el tiempo, se saldr\u00e1 del estado y no volver\u00e1 a entrar. Un estado recurrente es cualquier estado que no sea transitorio. En una cadena de Markov irreducible de estados finitos, todos los estados son recurrentes. Un caso especial de un estado recurrente es un estado absorbente, desde el cual no se puede alcanzar ning\u00fan otro estado. Se dice que un estado es peri\u00f3dico si est\u00e1 ocupado s\u00f3lo en momentos que difieren entre s\u00ed por m\u00faltiplos de alguna constante mayor que 1 1 .","title":"Cadenas de Markov"},{"location":"01cm_definiciones.html#cadenas-de-markov","text":"","title":"Cadenas de Markov"},{"location":"01cm_definiciones.html#transiciones-de-estado","text":"La secuencia de variables aleatorias x_0, x_1, x_2, \\dots, x_t , \\dots x_0, x_1, x_2, \\dots, x_t , \\dots representa un proceso estoc\u00e1stico . Cuando se indexan solamente los puntos en el tiempo en el que ocurren cambios significativos, se habla de procesos estoc\u00e1sticos de tiempo discreto . Hablamos de estado como la condici\u00f3n o caracter\u00edstica de un sistema en momento dado. Se asume que hay un n\u00famero finito de estados numerados 1, \\dots, N 1, \\dots, N que pueden describir al sistema en un cualquier momento. Cuando el sistema cambia de un estado a otro se dice que ocurre una transici\u00f3n . \\begin{equation} P (x_{t+1} = s_{t+1} | x_t = s_t , x_{t\u22121} = s_{t\u22121}, \\dots , x_1 = s_1, x_0 = s_0)\\\\ = P (x_{t+1} = s_{t+1} | x_t = s_t ) \\end{equation} \\begin{equation} P (x_{t+1} = s_{t+1} | x_t = s_t , x_{t\u22121} = s_{t\u22121}, \\dots , x_1 = s_1, x_0 = s_0)\\\\ = P (x_{t+1} = s_{t+1} | x_t = s_t ) \\end{equation} Se conoce como propiedad de Markov el hecho que la probabilidad del estado en t+1 t+1 dependa solamente del estado en t t . Y como cada x_t x_t depende tan solo de x_{t-1} x_{t-1} e influye solamente en x_{t+1} x_{t+1} se dice que el proceso es una cadena de Markov . Si, adem\u00e1s el n\u00famero de estados es numerable y finito, se habla de un cadena de Markov de estado finito . Una suposici\u00f3n adicional es que la probabilidad de transici\u00f3n de un estado i i a un estado j j es constante en el tiempo. \\begin{equation} P (x_{t+1} = j | x_t = i) = p_{ij} \\end{equation} \\begin{equation} P (x_{t+1} = j | x_t = i) = p_{ij} \\end{equation} es independiente del \u00edndice del tiempo t t , esto se conoce como la propiedad estacionaria . La probabilidad p_{ij} p_{ij} se denomina probabilidad de transici\u00f3n , al definirse para todos los estados del sistema i,j = 1, 2, \\dots, N i,j = 1, 2, \\dots, N , y se suelen escribir en una matriz de probabilidades de transici\u00f3n . \\begin{equation} \\mathbf{P} = \\begin{bmatrix} p_{11} & p_{12} & \\dots & p_{1N} \\\\ p_{21} & p_{22} & \\dots & p_{2N} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ p_{N1} & p_{N2} & \\dots & p_{NN} \\\\ \\end{bmatrix} \\end{equation} \\begin{equation} \\mathbf{P} = \\begin{bmatrix} p_{11} & p_{12} & \\dots & p_{1N} \\\\ p_{21} & p_{22} & \\dots & p_{2N} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ p_{N1} & p_{N2} & \\dots & p_{NN} \\\\ \\end{bmatrix} \\end{equation} Adem\u00e1s, los elementos de cada fila forma una distribuci\u00f3n de probabilidades discreta, por lo tanto: \\begin{equation} \\displaystyle\\sum_{j=1}^{N}p_{ij}=1 \\end{equation} \\begin{equation} \\displaystyle\\sum_{j=1}^{N}p_{ij}=1 \\end{equation} Un proceso de Markov comienza en alg\u00fan momento inicial t = 0 t = 0 . Si el estado x_0 x_0 no se conoce con certeza, entonces debemos especificar las probabilidades con las que el sistema se encuentra inicialmente en cada uno de los N N estados. Denotamos esto como P(x_0 = i) = p_i(0) P(x_0 = i) = p_i(0) para cada estado i i , y usamos el vector \\begin{equation} \\mathbf{p}(0) = [p_1(0), p_2(0), \\dots, p_N(0)] \\end{equation} \\begin{equation} \\mathbf{p}(0) = [p_1(0), p_2(0), \\dots, p_N(0)] \\end{equation} para describir la distribuci\u00f3n de probabilidad inicial del sistema.","title":"Transiciones de Estado"},{"location":"01cm_definiciones.html#ejemplo","text":"En un lugar se pueden describir los d\u00edas como soleados, nublados, y lluviosos. Despu\u00e9s de observar los patrones hist\u00f3ricos, la condici\u00f3n del clima del siguiente d\u00eda puede ser descrita de acuerdo a las siguientes probabilidades de transici\u00f3n: \\begin{equation} \\mathbf{P} = \\begin{bmatrix} 0.7 & 0.1 & 0.2 \\\\ 0.2 & 0.7 & 0.1 \\\\ 0.5 & 0.2 & 0.3 \\\\ \\end{bmatrix} \\end{equation} \\begin{equation} \\mathbf{P} = \\begin{bmatrix} 0.7 & 0.1 & 0.2 \\\\ 0.2 & 0.7 & 0.1 \\\\ 0.5 & 0.2 & 0.3 \\\\ \\end{bmatrix} \\end{equation} Las probabilidades de un paso pueden ilustrarse mediante un diagrama de transici\u00f3n de estados , en el que los estados se representan por nodos y las posibles transiciones como v\u00e9rtices . from graphviz import Digraph # Create Digraph object g = Digraph () g . attr ( rankdir = 'RL' , label = ' \\n Diagrama de transici\u00f3n' , fontsize = '16' , fontname = 'Lato' ) g . attr ( 'node' , fontsize = '10' , fontname = 'Lato' ) g . attr ( 'edge' , fontsize = '10' , fontname = 'Lato' ) # Add nodes g . node ( '1' , 'Soleado' ) g . node ( '2' , 'Nublado' ) g . node ( '3' , 'Lluvioso' ) # Add edges g . edge ( '1' , '1' , '0.7' ) g . edge ( '1' , '2' , '0.1' ) g . edge ( '1' , '3' , '0.2' ) g . edge ( '2' , '1' , '0.2' ) g . edge ( '2' , '2' , '0.7' ) g . edge ( '2' , '3' , '0.1' ) g . edge ( '3' , '1' , '0.5' ) g . edge ( '3' , '2' , '0.2' ) g . edge ( '3' , '3' , '0.3' ) # Visualize the graph g Si se desea conocer si una determinada condici\u00f3n del clima prevalece durante dos d\u00edas, se puede utilizar un \u00e1rbol de transici\u00f3n de dos pasos. g = Digraph () g . attr ( rankdir = 'LR' , label = ' \\n \u00c1rbol de transici\u00f3n' , fontsize = '16' , fontname = 'Lato' ) g . attr ( 'node' , fontsize = '10' , fontname = 'Lato' ) g . attr ( 'edge' , fontsize = '10' , fontname = 'Lato' ) g . node ( '1a' , 'Soleado' ) g . node ( '1b' , 'Soleado' ) g . node ( '2b' , 'Nublado' ) g . node ( '3b' , 'Lluvioso' ) g . node ( '1c' , 'Soleado' ) g . node ( '2c' , 'Nublado' ) g . node ( '3c' , 'Lluvioso' ) g . node ( '1d' , 'Soleado' ) g . node ( '2d' , 'Nublado' ) g . node ( '3d' , 'Lluvioso' ) g . node ( '1e' , 'Soleado' ) g . node ( '2e' , 'Nublado' ) g . node ( '3e' , 'Lluvioso' ) g . edge ( '1a' , '1b' , '0.7' ) g . edge ( '1a' , '2b' , '0.1' ) g . edge ( '1a' , '3b' , '0.2' ) g . edge ( '1b' , '1c' , '0.7' ) g . edge ( '1b' , '2c' , '0.1' ) g . edge ( '1b' , '3c' , '0.2' ) g . edge ( '2b' , '1d' , '0.2' ) g . edge ( '2b' , '2d' , '0.7' ) g . edge ( '2b' , '3d' , '0.1' ) g . edge ( '3b' , '1e' , '0.5' ) g . edge ( '3b' , '2e' , '0.2' ) g . edge ( '3b' , '3e' , '0.3' ) g","title":"Ejemplo"},{"location":"01cm_definiciones.html#probabilidades-de-estado","text":"Si se denota la probabilidad p_{ij}^{(n)} p_{ij}^{(n)} como la probabilidad de transici\u00f3n del estado i i al estado j j en n n pasos. El c\u00e1lculo de p_{11}^{(2)} p_{11}^{(2)} ser\u00eda \\begin{equation} (0.7)(0.7)+(0.1)(0.2)+(0.2)(0.5)\\\\ =(p_{11})(p_{11})+(p_{12})(p_{21})+(p_{13})(p_{31})\\\\ = 0.61 \\end{equation} \\begin{equation} (0.7)(0.7)+(0.1)(0.2)+(0.2)(0.5)\\\\ =(p_{11})(p_{11})+(p_{12})(p_{21})+(p_{13})(p_{31})\\\\ = 0.61 \\end{equation} Es posible generalizar que para cualquier i i y j j , p_{ij}^{(2)} p_{ij}^{(2)} es el producto interno de la i i -\u00e9sima fila de \\mathbf{P} \\mathbf{P} con la j j -\u00e9sima columna de \\mathbf{P} \\mathbf{P} . \\begin{equation} p_{ij}^{(2)} = \\sum_{k=1}^{N}p_{ik}p_{kj} \\end{equation} \\begin{equation} p_{ij}^{(2)} = \\sum_{k=1}^{N}p_{ik}p_{kj} \\end{equation} import numpy as np p = np . array ([[ 0.7 , 0.1 , 0.2 ], [ 0.2 , 0.7 , 0.1 ], [ 0.5 , 0.2 , 0.3 ]]) p array ([[ 0 . 7 , 0 . 1 , 0 . 2 ], [ 0 . 2 , 0 . 7 , 0 . 1 ], [ 0 . 5 , 0 . 2 , 0 . 3 ]]) p2 = p @ p p2 array ([[ 0 . 61 , 0 . 18 , 0 . 21 ], [ 0 . 33 , 0 . 53 , 0 . 14 ], [ 0 . 54 , 0 . 25 , 0 . 21 ]]) from IPython.display import display , Markdown display ( Markdown ( rf '$p^2_{{11}} =$ {p2[0, 0]:.2f}' )) p^2_{11} = p^2_{11} = 0.61 Lo que implica que la probabilidad que sea soleado dentro de dos d\u00edas dado que hoy es soleado es igual a 0.61 0.61 . Siendo @ en numpy el operador para la multiplicaci\u00f3n matricial o la multiplicaci\u00f3n punto, siendo p @ p equivalente a p . dot ( p ) . Se puede generalizar a\u00fan m\u00e1s esta expresi\u00f3n, llegando a lo que se conoce como la Ecuaci\u00f3n de Chapman-Kolgomorov : \\begin{equation} p_{ij}^{(n)} = p_{ij}^{n} = \\sum_{k=1}^{N}p_{ik}^{n-m}p_{kj}^m \\end{equation} \\begin{equation} p_{ij}^{(n)} = p_{ij}^{n} = \\sum_{k=1}^{N}p_{ik}^{n-m}p_{kj}^m \\end{equation}","title":"Probabilidades de Estado"},{"location":"01cm_definiciones.html#clasificacion-de-los-estados-en-un-proceso-de-markov","text":"Un estado j j es alcanzable desde el estado i i si hay una secuencia de transiciones que comienza en estado i i y termina en estado j j . Esto es, p^{(n)}_{ij} \\gt 0 p^{(n)}_{ij} \\gt 0 para alg\u00fan n n . Una cadena Markov irreducible es aquella en la que se puede llegar a todos los estados desde todos los dem\u00e1s estados. Es decir, en una cadena irreducible, no es posible que el proceso quede atrapado y de ah\u00ed en adelante solo pueda hacer transiciones dentro de alg\u00fan subconjunto de los estados. Se dice que un conjunto de estados est\u00e1 cerrado si no se puede llegar a ning\u00fan estado fuera del conjunto desde ning\u00fan estado dentro del conjunto. Esto significa que una vez que el sistema entra en cualquier estado en el conjunto, nunca saldr\u00e1 de este conjunto. En una cadena irreducible, sus estados constituyen un conjunto cerrado y ning\u00fan subconjunto de estos estados est\u00e1 cerrado. Un caso particularmente interesante se presenta si un conjunto cerrado contiene s\u00f3lo un estado. Este estado i i se llama estado absorbente , y p_{ii} = 1 p_{ii} = 1 . El sistema nunca deja un estado de absorci\u00f3n. Un estado i i es un estado transitorio si hay una transici\u00f3n del estado i i a otro estado j j desde la cual no se puede volver a alcanzar el estado i i . Por lo tanto, siempre que se sale de un estado transitorio, hay una probabilidad positiva de que no se vuelva a ocupar nunca m\u00e1s. Y por lo tanto, la probabilidad a largo plazo de que un sistema se encuentre en un estado transitorio es esencialmente nula porque, con el tiempo, se saldr\u00e1 del estado y no volver\u00e1 a entrar. Un estado recurrente es cualquier estado que no sea transitorio. En una cadena de Markov irreducible de estados finitos, todos los estados son recurrentes. Un caso especial de un estado recurrente es un estado absorbente, desde el cual no se puede alcanzar ning\u00fan otro estado. Se dice que un estado es peri\u00f3dico si est\u00e1 ocupado s\u00f3lo en momentos que difieren entre s\u00ed por m\u00faltiplos de alguna constante mayor que 1 1 .","title":"Clasificaci\u00f3n de los estados en un proceso de Markov"},{"location":"02cm_estado_estable.html","text":"An\u00e1lisis de Estado Estable \u00b6 Probabilidades de estado estable \u00b6 Podemos utilizar la ecuaci\u00f3n de Chapman-Kolgomorov para analizar la evoluci\u00f3n de las probabilidades de transici\u00f3n de n n -pasos. Utilicemos los datos de la parte anterior: import numpy as np p = np . array ([[ 0.7 , 0.1 , 0.2 ], [ 0.2 , 0.7 , 0.1 ], [ 0.5 , 0.2 , 0.3 ]]) p array ([[ 0 . 7 , 0 . 1 , 0 . 2 ], [ 0 . 2 , 0 . 7 , 0 . 1 ], [ 0 . 5 , 0 . 2 , 0 . 3 ]]) p2 = p @ p p2 array ([[ 0 . 61 , 0 . 18 , 0 . 21 ], [ 0 . 33 , 0 . 53 , 0 . 14 ], [ 0 . 54 , 0 . 25 , 0 . 21 ]]) p4 = p2 @ p2 p4 array ([[ 0 . 5449 , 0 . 2577 , 0 . 1974 ], [ 0 . 4518 , 0 . 3753 , 0 . 1729 ], [ 0 . 5253 , 0 . 2822 , 0 . 1925 ]]) p8 = p4 @ p4 p8 array ([[ 0 . 51703909 , 0 . 29284182 , 0 . 19011909 ], [ 0 . 50657073 , 0 . 30607133 , 0 . 18735794 ], [ 0 . 51485418 , 0 . 29560297 , 0 . 18954285 ]]) p16 = p8 @ p8 p16 array ([[ 0 . 51355812 , 0 . 29724092 , 0 . 18920096 ], [ 0 . 51342566 , 0 . 29740832 , 0 . 18916602 ], [ 0 . 51353048 , 0 . 29727586 , 0 . 18919366 ]]) En este caso, es notable observar como los valores en cada columna van convergiendo a un mismo valor. Esta es una propiedad que tienen todas las cadenas de Markov que forman un conjunto irreducible no peri\u00f3dico. Estas cadenas tambi\u00e9n se conocen como erg\u00f3dicas . import matplotlib.pyplot as plt fig , ax = plt . subplots () nt = 15 pt = np . empty ( 3 * 3 * nt ) pt . shape = ( 3 , 3 , nt ) p_aux = p n , m = p . shape for t in range ( nt ): pt [:, :, t ] = p_aux p_aux = p_aux @ p for j in range ( n ): for k in range ( m ): plt . plot ( pt [ k , j ], color = f \"#{format(k*96, '02x')}{format(j*96, '02x')}32\" , label = f '$p_{{{k}{j}}}$' ) ax . set_xlabel ( 'n-\u00e9sima potencia de $\\mathbf{P}$' ) ax . set_ylabel ( 'Probabilidad' ) plt . legend ( loc = 'lower right' , bbox_to_anchor = ( 1.2 , 0 )) plt . show () Se puede observar que cada grupo de l\u00edneas que corresponden a las probabilidades de n-\u00e9simo paso de una misma columna convergen. Estos valores a los que convergen todos los valores de una misma columna se conocen como Probabilidades de estado estable que se denotan por \\mathbf{\\Pi} = \\lim\\limits_{n \\to \\infty}\\mathbf{P}^n \\mathbf{\\Pi} = \\lim\\limits_{n \\to \\infty}\\mathbf{P}^n , y pueden calcularse directamente observando que en alg\u00fan momento: \\begin{equation} \\mathbf{\\Pi} \\cdot \\mathbf{P} = \\mathbf{\\Pi} \\end{equation} \\begin{equation} \\mathbf{\\Pi} \\cdot \\mathbf{P} = \\mathbf{\\Pi} \\end{equation} Lo que implica que: \\begin{equation} \\pi_j = \\sum_{i=1}^{N}\\pi_i p_{ij}~\\forall j=1, 2, \\dots, N \\end{equation} \\begin{equation} \\pi_j = \\sum_{i=1}^{N}\\pi_i p_{ij}~\\forall j=1, 2, \\dots, N \\end{equation} Esto conduce al sistema de ecuaciones: \\begin{equation} [\\mathbf{P}^t - \\mathbf{I}]~\\mathbf{\\Pi} = \\mathbf{0} \\end{equation} \\begin{equation} [\\mathbf{P}^t - \\mathbf{I}]~\\mathbf{\\Pi} = \\mathbf{0} \\end{equation} Como todas las ecuaciones quedan igualadas a cero se genera una dependencia lineal, por lo que se debe sustituir una de estas ecuaciones (es decir, una fila del sistema anterior) por el hecho que: \\begin{equation} \\sum_{i=1}^{N}\\pi_i = 1 \\end{equation} \\begin{equation} \\sum_{i=1}^{N}\\pi_i = 1 \\end{equation} As\u00ed, podemos resolverlo matricialmente mediante la siguiente funci\u00f3n: def steady_state ( p ): n = p . shape [ 0 ] a = p . T - np . eye ( n ) a [ n - 1 , :] = np . ones ( n ) b = np . append ( np . zeros ( n - 1 ), 1 ) return np . linalg . solve ( a , b ) from IPython.display import display , Markdown pi = steady_state ( p ) display ( Markdown ( rf '$\\pi_{{1}} =$ {pi[0]:.6f}' )) display ( Markdown ( rf '$\\pi_{{2}} =$ {pi[1]:.6f}' )) display ( Markdown ( rf '$\\pi_{{3}} =$ {pi[2]:.6f}' )) \\pi_{1} = \\pi_{1} = 0.513514 \\pi_{2} = \\pi_{2} = 0.297297 \\pi_{3} = \\pi_{3} = 0.189189 La forma b\u00e1sica en la que pueden interpretarse estos valores es la probabilidad de que el sistema (representado por la cadena de markov) se encuentre en uno estado espec\u00edfico despu\u00e9s de un n\u00famero suficientemente grande de transiciones. En este caso, \\pi_{1} = 0.513514 \\pi_{1} = 0.513514 indica que la probabilidad de conseguir un d\u00eda soleado dentro de 100 o 200 d\u00edas es aproximadamente 0.51 0.51 , independientemente del estado del clima de hoy. Hay otra interpretaci\u00f3n probablemente m\u00e1s interesante de las probabilidades de estado estable, a partir del propio concepto de la probabilidad como frecuencia relativa, y es que de un n\u00famero suficientemente grande de d\u00edas, estas probabilidades representan el n\u00famero de estimado de ocurrencias de un estado. En este caso, en un a\u00f1o el n\u00famero de d\u00edas soleados estar\u00eda dado por: 365 * pi [ 0 ] 187 . 4324324324324 Esto indica que poco m\u00e1s de 187 187 d\u00edas al a\u00f1o ser\u00e1n soleados. Y en general, que el 51.35 \\% 51.35 \\% de los d\u00edas ser\u00e1n soleados.","title":"An\u00e1lisis de Estado Estable"},{"location":"02cm_estado_estable.html#analisis-de-estado-estable","text":"","title":"An\u00e1lisis de Estado Estable"},{"location":"02cm_estado_estable.html#probabilidades-de-estado-estable","text":"Podemos utilizar la ecuaci\u00f3n de Chapman-Kolgomorov para analizar la evoluci\u00f3n de las probabilidades de transici\u00f3n de n n -pasos. Utilicemos los datos de la parte anterior: import numpy as np p = np . array ([[ 0.7 , 0.1 , 0.2 ], [ 0.2 , 0.7 , 0.1 ], [ 0.5 , 0.2 , 0.3 ]]) p array ([[ 0 . 7 , 0 . 1 , 0 . 2 ], [ 0 . 2 , 0 . 7 , 0 . 1 ], [ 0 . 5 , 0 . 2 , 0 . 3 ]]) p2 = p @ p p2 array ([[ 0 . 61 , 0 . 18 , 0 . 21 ], [ 0 . 33 , 0 . 53 , 0 . 14 ], [ 0 . 54 , 0 . 25 , 0 . 21 ]]) p4 = p2 @ p2 p4 array ([[ 0 . 5449 , 0 . 2577 , 0 . 1974 ], [ 0 . 4518 , 0 . 3753 , 0 . 1729 ], [ 0 . 5253 , 0 . 2822 , 0 . 1925 ]]) p8 = p4 @ p4 p8 array ([[ 0 . 51703909 , 0 . 29284182 , 0 . 19011909 ], [ 0 . 50657073 , 0 . 30607133 , 0 . 18735794 ], [ 0 . 51485418 , 0 . 29560297 , 0 . 18954285 ]]) p16 = p8 @ p8 p16 array ([[ 0 . 51355812 , 0 . 29724092 , 0 . 18920096 ], [ 0 . 51342566 , 0 . 29740832 , 0 . 18916602 ], [ 0 . 51353048 , 0 . 29727586 , 0 . 18919366 ]]) En este caso, es notable observar como los valores en cada columna van convergiendo a un mismo valor. Esta es una propiedad que tienen todas las cadenas de Markov que forman un conjunto irreducible no peri\u00f3dico. Estas cadenas tambi\u00e9n se conocen como erg\u00f3dicas . import matplotlib.pyplot as plt fig , ax = plt . subplots () nt = 15 pt = np . empty ( 3 * 3 * nt ) pt . shape = ( 3 , 3 , nt ) p_aux = p n , m = p . shape for t in range ( nt ): pt [:, :, t ] = p_aux p_aux = p_aux @ p for j in range ( n ): for k in range ( m ): plt . plot ( pt [ k , j ], color = f \"#{format(k*96, '02x')}{format(j*96, '02x')}32\" , label = f '$p_{{{k}{j}}}$' ) ax . set_xlabel ( 'n-\u00e9sima potencia de $\\mathbf{P}$' ) ax . set_ylabel ( 'Probabilidad' ) plt . legend ( loc = 'lower right' , bbox_to_anchor = ( 1.2 , 0 )) plt . show () Se puede observar que cada grupo de l\u00edneas que corresponden a las probabilidades de n-\u00e9simo paso de una misma columna convergen. Estos valores a los que convergen todos los valores de una misma columna se conocen como Probabilidades de estado estable que se denotan por \\mathbf{\\Pi} = \\lim\\limits_{n \\to \\infty}\\mathbf{P}^n \\mathbf{\\Pi} = \\lim\\limits_{n \\to \\infty}\\mathbf{P}^n , y pueden calcularse directamente observando que en alg\u00fan momento: \\begin{equation} \\mathbf{\\Pi} \\cdot \\mathbf{P} = \\mathbf{\\Pi} \\end{equation} \\begin{equation} \\mathbf{\\Pi} \\cdot \\mathbf{P} = \\mathbf{\\Pi} \\end{equation} Lo que implica que: \\begin{equation} \\pi_j = \\sum_{i=1}^{N}\\pi_i p_{ij}~\\forall j=1, 2, \\dots, N \\end{equation} \\begin{equation} \\pi_j = \\sum_{i=1}^{N}\\pi_i p_{ij}~\\forall j=1, 2, \\dots, N \\end{equation} Esto conduce al sistema de ecuaciones: \\begin{equation} [\\mathbf{P}^t - \\mathbf{I}]~\\mathbf{\\Pi} = \\mathbf{0} \\end{equation} \\begin{equation} [\\mathbf{P}^t - \\mathbf{I}]~\\mathbf{\\Pi} = \\mathbf{0} \\end{equation} Como todas las ecuaciones quedan igualadas a cero se genera una dependencia lineal, por lo que se debe sustituir una de estas ecuaciones (es decir, una fila del sistema anterior) por el hecho que: \\begin{equation} \\sum_{i=1}^{N}\\pi_i = 1 \\end{equation} \\begin{equation} \\sum_{i=1}^{N}\\pi_i = 1 \\end{equation} As\u00ed, podemos resolverlo matricialmente mediante la siguiente funci\u00f3n: def steady_state ( p ): n = p . shape [ 0 ] a = p . T - np . eye ( n ) a [ n - 1 , :] = np . ones ( n ) b = np . append ( np . zeros ( n - 1 ), 1 ) return np . linalg . solve ( a , b ) from IPython.display import display , Markdown pi = steady_state ( p ) display ( Markdown ( rf '$\\pi_{{1}} =$ {pi[0]:.6f}' )) display ( Markdown ( rf '$\\pi_{{2}} =$ {pi[1]:.6f}' )) display ( Markdown ( rf '$\\pi_{{3}} =$ {pi[2]:.6f}' )) \\pi_{1} = \\pi_{1} = 0.513514 \\pi_{2} = \\pi_{2} = 0.297297 \\pi_{3} = \\pi_{3} = 0.189189 La forma b\u00e1sica en la que pueden interpretarse estos valores es la probabilidad de que el sistema (representado por la cadena de markov) se encuentre en uno estado espec\u00edfico despu\u00e9s de un n\u00famero suficientemente grande de transiciones. En este caso, \\pi_{1} = 0.513514 \\pi_{1} = 0.513514 indica que la probabilidad de conseguir un d\u00eda soleado dentro de 100 o 200 d\u00edas es aproximadamente 0.51 0.51 , independientemente del estado del clima de hoy. Hay otra interpretaci\u00f3n probablemente m\u00e1s interesante de las probabilidades de estado estable, a partir del propio concepto de la probabilidad como frecuencia relativa, y es que de un n\u00famero suficientemente grande de d\u00edas, estas probabilidades representan el n\u00famero de estimado de ocurrencias de un estado. En este caso, en un a\u00f1o el n\u00famero de d\u00edas soleados estar\u00eda dado por: 365 * pi [ 0 ] 187 . 4324324324324 Esto indica que poco m\u00e1s de 187 187 d\u00edas al a\u00f1o ser\u00e1n soleados. Y en general, que el 51.35 \\% 51.35 \\% de los d\u00edas ser\u00e1n soleados.","title":"Probabilidades de estado estable"}]}